# Adaptive Fourier Neural Operator Configuration
# Efficient token mixing with adaptive mode truncation
# Paper: "Adaptive Fourier neural operators: Efficient token mixers for transformers" (2022)

model:
  model_type: "afno"
  hidden_dim: 768
  num_layers: 12
  sequence_length: 512
  dropout: 0.1
  vocab_size: 50000
  num_classes: 10
  ffn_hidden_dim: 3072
  use_positional_encoding: true
  positional_encoding_type: "sinusoidal"
  norm_eps: 1e-12
  output_type: "classification"
  gradient_checkpointing: false
  # AFNO-specific parameters
  n_modes: 256  # Number of Fourier modes to retain
  modes_seq: 256  # Modes in sequence dimension
  modes_hidden: 384  # Modes in hidden dimension
  compression_ratio: 0.5
  mlp_ratio: 2.0

# Layer-specific configurations
layers:
  mixing:
    type: "afno"
    hidden_dim: 768
    max_sequence_length: 512
    modes_seq: 256
    modes_hidden: 384
    mlp_ratio: 2.0
    activation: "gelu"
    dropout: 0.1
    
  ffn:
    hidden_dim: 768
    intermediate_dim: 3072
    activation: "gelu"
    dropout: 0.1

# Training configuration
training:
  batch_size: 16  # Smaller batch size due to higher memory usage
  learning_rate: 1e-4
  weight_decay: 0.01
  warmup_steps: 8000
  max_steps: 200000
  save_steps: 2000
  eval_steps: 1000
  gradient_accumulation_steps: 2